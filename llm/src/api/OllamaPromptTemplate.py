# Import the necessary classes
from fastapi import HTTPException
from langchain_core.prompts import ChatPromptTemplate
from llm.src.conf.Prompts import default_prompt1
from llm.src.utilities.OllamaPipeline import OllamaPipeline
from llm.src.conf.Configurations import logger


def qa_with_ollama(context: str, questions: list[str]):
    """
    Perform question answering using the Ollama model
    :param context: The context in which to answer the question.
    :param questions: The question to answer.
    :return: The answer generated by the Ollama model.
    """

    # Load the Ollama model
    model = OllamaPipeline().get_model()
    logger.info("Model initialized.")

    pre_prompt = f"""{default_prompt1}"""

    # Define the prompt template
    template = """CONTEXT:{context}

    Question: {question}

    Answer: Just give a simple and precise answer. If the answer cannot be found in the context, respond with "Answer not found in context"."""
    prompt = ChatPromptTemplate.from_template(template)


    # Invoke the chain with a question
    try:

        response = []

        for question in questions:
            # Format the prompt with the question input
            formatted_prompt = prompt.format_prompt(question=question, context=context)

            # Directly invoke the model with the formatted prompt
            logger.info("invoking the model with the formatted prompt")
            simple_response = model.invoke(formatted_prompt)
            logger.info("response received from the model")

            response.append(simple_response)

        return response

    except Exception as e:

        raise HTTPException(status_code=500, detail=f"An error occurred during invocation: {e}")


if __name__ == "__main__":

    sample_context = "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines designed to think and learn like humans. AI systems can perform tasks such as image recognition, natural language processing, decision-making, and autonomous driving. Machine learning (ML) is a subset of AI that allows computers to learn from data and improve their performance without being explicitly programmed. Deep learning, a type of machine learning, uses neural networks with many layers to analyze large datasets. AI has applications across various industries, including healthcare, finance, and entertainment, and continues to evolve as computing power increases"

    Questions = [
        "What is the difference between AI and machine learning?",
        "How does deep learning work in artificial intelligence?",
        "Who is the founder of AI?",  # Out of context
        "What are the ethical concerns surrounding the use of AI in surveillance?"  # Out of context
    ]

    res = qa_with_ollama(sample_context, Questions)

    for answer,Question in zip(res,Questions):
        print(f"Question: {Question}\nAnswer: {answer}\n")





